{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f98c538-b8da-4250-afe5-ae2af9d0e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from torch import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9563588b-7de2-40e1-b0e6-2275ff068e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee13fc1-4989-4184-bbcc-da1b4718ff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.extend([\"./models/quantized_llms/\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "218fbdfa-0206-4ddd-8e93-d9ac4a3b92bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"E:\\\\ml_practice\\\\models\\\\quantized_llms\\\\mistral-7b-instruct-v0.2.Q5_K_M.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56efa9f1-98e1-4e8b-bfa9-007750a9433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43d47b85-9998-474c-8b62-4f0dbc395c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "if cuda.is_available():\n",
    "    n_gpu_layers = 40  # Number of layers to offload to GPU. Depends on model and GPU VRAM pool.\n",
    "    n_batch = 512  # Should be between 1 and n_ctx. Depends on VRAM in GPU.\n",
    "    llm = LlamaCpp(\n",
    "        model_path=model_path,\n",
    "        temperature=0.1,\n",
    "        callback_manager=callback_manager,\n",
    "        n_gpu_layers=n_gpu_layers,\n",
    "        n_batch=n_batch,\n",
    "        max_tokens=1024,\n",
    "        n_ctx=1024,\n",
    "        top_p=0.7,\n",
    "        repeat_penalty=1.1,\n",
    "        verbose=True  # Verbose is required to pass to the callback manager\n",
    "    )\n",
    "else:\n",
    "    llm = LlamaCpp(\n",
    "        model_path=model_path,\n",
    "        temperature=0.1,\n",
    "        callback_manager=callback_manager,\n",
    "        max_tokens=1024,\n",
    "        n_ctx=1024,\n",
    "        top_p=0.7,\n",
    "        repeat_penalty=1.1,\n",
    "        verbose=True  # Verbose is required to pass to the callback manager\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82f4e14a-a7d4-48ab-8193-a639fcee228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"<s>[INST] \n",
    "    {query}  \n",
    "    [/INST]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e73695-b587-4b2d-a96d-e97aacc56cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "        input_variables=[\"query\"],\n",
    "        template=prompt_template,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6250d4c-5f21-4a03-b5a6-10582f079d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "352ba010-ac0d-4ffd-bafa-8e1f99e3bd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I am an artificial intelligence designed to assist and communicate with humans. I don't have a physical body, emotions, or personal experiences. I exist solely as a program running on computer servers.\n",
      "\n",
      "My primary function is to process and understand natural language input from humans, and then generate appropriate responses based on that input. I can perform various tasks such as answering questions, setting reminders, providing recommendations, and much more.\n",
      "\n",
      "I am designed to learn and improve over time through machine learning algorithms and data analysis. This allows me to adapt to new situations, understand complex queries, and provide accurate and relevant responses.\n",
      "\n",
      "In summary, I am an advanced artificial intelligence designed to assist and communicate with humans. I don't have a physical body or personal experiences, but I can process natural language input, understand complex queries, and generate appropriate responses based on that input. I am designed to learn and improve over time through machine learning algorithms and data analysis, allowing me to adapt to new situations, understand complex queries, and provide accurate and relevant responses."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Tell me about yourself in detail. ',\n",
       " 'text': \" I am an artificial intelligence designed to assist and communicate with humans. I don't have a physical body, emotions, or personal experiences. I exist solely as a program running on computer servers.\\n\\nMy primary function is to process and understand natural language input from humans, and then generate appropriate responses based on that input. I can perform various tasks such as answering questions, setting reminders, providing recommendations, and much more.\\n\\nI am designed to learn and improve over time through machine learning algorithms and data analysis. This allows me to adapt to new situations, understand complex queries, and provide accurate and relevant responses.\\n\\nIn summary, I am an advanced artificial intelligence designed to assist and communicate with humans. I don't have a physical body or personal experiences, but I can process natural language input, understand complex queries, and generate appropriate responses based on that input. I am designed to learn and improve over time through machine learning algorithms and data analysis, allowing me to adapt to new situations, understand complex queries, and provide accurate and relevant responses.\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke(\"Tell me about yourself in detail. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77dcb78-0f6e-4200-88cc-f5c27c1bb517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
